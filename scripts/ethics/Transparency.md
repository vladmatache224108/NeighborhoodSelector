
# REQUIREMENT #4 Transparency
A crucial component of achieving Trustworthy AI is transparency which encompasses three
elements:
1) traceability, 
2) explainability
3) open communication about the limitations of the AI system.

Glossary: AI System; End-User; Explicability; Lifecycle; Subject; Traceability; Workflow of
the Model.
Traceability
This subsection helps to self-assess whether the processes of the development of the AI
system, i.e. the data and processes that yield the AI system’s decisions, is properly
documented to allow for traceability, increase transparency and, ultimately, build trust in AI
in society.
##  Did you put in place measures that address the traceability of the AI system during its entire lifecycle?

No, we did not put in place measures to trace the AI system during its entire lifecycle.


##  Did you put in place measures to continuously assess the quality of the input data to the AI system?

Yes, we put in place measures to continuously assess the quality of the input data to the AI system.


##  Can you trace back which data was used by the AI system to make a certain decision(s) or recommendation(s)?

Yes, we can trace back which data was used by the AI system to make certain decision(s) or recommendation(s).


##  Can you trace back which AI model or rules led to the decision(s) or recommendation(s) of the AI system?

Yes, we can trace back which AI model or rules led to the decision(s) or recommendation(s) of the AI system.


##  Did you put in place measures to continuously assess the quality of the output(s) of the AI system?

Yes, we put in place measures to continuously assess the quality of the output(s) of the AI system.


##  Did you put adequate logging practices in place to record the decision(s) or recommendation(s) of the AI system?

Yes, we put adequate logging practices in place to record the decision(s) or recommendation(s) of the AI system.



# Explainability
This subsection helps to self-assess the explainability of the AI system. The questions refer
to the ability to explain both the technical processes of the AI system and the reasoning
behind the decisions or predictions that the AI system makes. Explainability is crucial for
building and maintaining users’ trust in AI systems. AI driven decisions – to the extent
possible – must be explained to and understood by those directly and indirectly affected, in
order to allow for contesting of such decisions. An explanation as to why a model has
generated a particular output or decision (and what combination of input factors contributed
to that) is not always possible. These cases are referred to as ‘blackboxes' and require
special attention. In those circumstances, other explainability measures (e.g. traceability,
auditability and transparent communication on the AI system’s capabilities) may be required,
provided that the AI system as a whole respects fundamental rights. The degree to which
explainability is needed depends on the context and the severity of the consequences of
erroneous or otherwise inaccurate output to human life.


## Did you explain the decision(s) of the AI system to the users?

As a school project without a deployed AI system, we could not have explained the decision(s) of the AI system to the users.


## Do you continuously survey the users if they understand the decision(s) of the AI system?

As a school project without a deployed AI system, we could not have continuously surveyed the users if they understand the decision(s) of the AI system special attention. In those circumstances, other explainability measures (e.g. traceability,
auditability and transparent communication on the AI system’s capabilities) may be required,
provided that the AI system as a whole respects fundamental rights. The degree to which
explainability is needed depends on the context and the severity of the consequences of
erroneous or otherwise inaccurate output to human life.


## Did you explain the decision(s) of the AI system to the users?

As a school project without a deployed AI system, we could not have explained the decision(s) of the AI system to the users.


## Do you continuously survey the users if they understand the decision(s) of the AI system?’**

As a school project without a deployed AI system, we could not have continuously surveyed the users if they understand the decision(s) of the AI system.



# Communication
This subsection helps to self-assess whether the AI system’s capabilities and limitations
have been communicated to the users in a manner appropriate to the use case at hand. This
could encompass communication of the AI system's level of accuracy as well as its
limitations.
## In cases of interactive AI systems (e.g., chatbots, robo-lawyers), do you communicate to users that they are interacting with an AI system instead of a human?

As a school project without a deployed AI system, we cannot say if we would communicate to users if they are interacting with an AI system instead of a human. However, in cases of interactive AI systems, it is important to inform users about who or what they are interacting with to avoid confusion.


## Did you establish mechanisms to inform users about the purpose, criteria and limitations of the decision(s) generated by the AI system?

As a school project without a deployed AI system, we cannot say if we established mechanisms to inform users about the purpose, criteria and limitations of the decision(s) generated by the AI system.


##  Did you communicate the benefits of the AI system to users?

As a school project without a deployed AI system, we cannot say if we communicated the benefits of the AI system to users. However, communicating the benefits of an AI system to users is important to build trust and explain the purpose of the system.


##  Did you communicate the technical limitations and potential risks of the AI system to users, such as its level of accuracy and/ or error rates?

As a school project without a deployed AI system, we cannot say if we communicated the benefits of the AI system to users. However, communicating the benefits of an AI system to users is important to build trust and explain the purpose of the system.


##  Did you provide appropriate training material and disclaimers to users on how to adequately use the AI system?

As a school project without a deployed AI system, we cannot say if we provided appropriate training material and disclaimers to users on how to adequately use the AI system. However, it is important to provide such material to help users effectively interact with the AI system and manage their expectations.

