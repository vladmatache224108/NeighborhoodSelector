# Human Agency and Autonomy

## Is the AI system designed to interact, guide or take decisions by human end-users that affect humans or society? 

The AI system predicts house values, but it should not be the sole basis for decision-making with potential impacts on humans or society. Our recommendation is to involve humans in the final decision-making process, utilizing the AI-generated data as a tool to enhance decision-making capabilities.

## Are end-users or other subjects adequately made aware that a decision, content, advice or outcome is the result of an algorithmic decision? 

Yes, end-users and other subjects are made aware that a decision, content, advice, or outcome is the result of an algorithmic decision. The AI system is designed to provide clear explanations for its predictive models.


## Could the AI system generate confusion for some or all end-users or subjects on whether they are interacting with a human or AI system? 

Yes, the AI system can generate confusion for some users, as it is designed to simulate human-like interactions. Providing transparency about the AI nature of the system is crucial to manage user expectations and minimize confusion.

## Are end-users or subjects informed that they are interacting with an AI system? 

Yes, end-users and subjects are informed that they are interacting with an AI system. The AI system is designed to provide clear indications that it is an AI system to avoid confusion.

## Could the AI system affect human autonomy by generating over-reliance by end-users? 

It is possible for the AI system to generate over-reliance among end-users, which can potentially impact human autonomy. However, to mitigate this reliance on our model, we have recommended not to use it due to its lack of satisfactory performance. By acknowledging its limitations and suggesting alternative approaches or models that demonstrate better performance, we aim to promote user autonomy and encourage informed decision-making beyond the scope of our AI system. 


## Did you put in place procedures to avoid that end-users over-rely on the AI system? 

Yes, we have implemented procedures to prevent end-users from over-relying on the AI system. While the AI system provides recommendations and predictions, it is made clear that the ultimate decision-making authority rests with the end-user. We emphasize the importance of considering multiple factors, seeking additional information, and exercising human judgment in the decision-making process. Additionally, due to the AI system's poor prediction performance, we strongly recommended against relying solely on its outputs for decision-making purposes. 

## Could the AI system affect human autonomy by interfering with the end-user’s decision-making process in any other unintended and undesirable way? 

After evaluating the performance of the Random Forest model, the obtained accuracy scores did not meet our satisfactory standards. Therefore, we cannot recommend its usage as it does not make proper predictions. It is essential to rely on models that demonstrate higher accuracy and reliability in order to make informed decisions.

## Did you put in place any procedure to avoid that the AI system inadvertently affects human autonomy? 

Yes, we have put in place several procedures to avoid the AI system inadvertently affecting human autonomy. We have designed the system to provide transparent and interpretable results, ensuring that the end-users understand the logic behind the recommendations, enabling them to make informed decisions while using the AI's results as a tool.


## Does the AI system simulate social interaction with or between end-users or subjects? 

No, the AI system does not simulate social interaction with or between end-users or subjects. Its main goal is to provide predictive models and insights related to house value, and it does so without creating or simulating any social interaction between end-users or subjects.


Human Oversight


## Is a self-learning or autonomous system?

The AI model we are using is self-learning since it relies on input-output mechanisms and does not have the ability to make decisions autonomously.


## Is overseen by a Human-in-the-Loop?

Yes, the AI system is overseen by a Human-in-the-Loop. This means that human operators or experts are involved in the monitoring and decision-making process, ensuring that the AI system's outputs are reviewed, validated, and guided by human judgment. The human operators play an active role in supervising and controlling the system's operations.

## Is overseen by a Human-on-the-Loop?

No, the AI system is not overseen by a Human-on-the-Loop. The system's outputs are not actively monitored or reviewed by humans in real-time. 


## Is overseen by a Human-in-Command?

Not applicable in this context, as the term "Human-in-Command" typically refers to situations where a human has direct control and decision-making authority over a system or operation. In the case of the AI system, it is supervised and guided by humans, but it does not involve direct command or control over a physical or operational entity.


## Have the humans (human-in-the-loop, human-on-the-loop, human-in-command) been given specific training on how to exercise oversight? 

No, specific training on how to exercise oversight has not been provided to us, involved in the AI system (human-in-the-loop, human-on-the-loop, human-in-command) as it is not applicable in this context.

## Did you establish any detection and response mechanisms for undesirable adverse effects of the AI system for the end-user or subject? 

We check all the results of our self-learning to make sure that the final product doesn't have any unwanted negative effects.

## Did you ensure a ‘stop button’ or procedure to safely abort an operation when needed? 

We use Visual Studio Code for training the model, and we can stop it at any time using the stop function.

## Did you take any specific oversight and control measures to reflect the self-learning or autonomous nature of the AI system?  

As a team, we have delved into DEDA and ALTA frameworks and also ethics in AI. This enables us to reflect on any potential biases or undesirable conclusions.
