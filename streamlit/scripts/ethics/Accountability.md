
# REQUIREMENT #7 Accountability
The principle of accountability necessitates that mechanisms be put in place to ensure
responsibility for the development, deployment and/or use of AI systems. This topic is
closely related to risk management, identifying and mitigating risks in a transparent way that
can be explained to and audited by third parties. When unjust or adverse impacts occur,
accessible mechanisms for accountability should be in place that ensure an adequate
possibility of redress.
Glossary: Accountability; AI Ethics Review Board; Redress by Design.
Auditability
This subsection helps to self-assess the existing or necessary level that would be required
for an evaluation of the AI system by internal and external auditors. The possibility to
conduct evaluations as well as to access records on said evaluations can contribute to
Trustworthy AI. In applications affecting fundamental rights, including safety-critical
applications, AI systems should be able to be independently audited. This does not
necessarily imply that information about business models and intellectual property related to
the AI system must always be openly available.

## Did you establish mechanisms that facilitate the AI system's auditability (e.g. traceability of the development process, the sourcing of training data and the logging of the AI system's processes, outcomes, positive and negative impact)?

Yes, it is important to establish mechanisms that facilitate the auditability of the AI system, such as traceability of the development process, sourcing of training data, and logging of the AI system's processes, outcomes, and positive and negative impacts. Our team has taken steps by using Trello and GitHub to evidence the whole process.	

[Trello](https://trello.com/b/3fUGzIHG/geoninjas)

[Github](https://github.com/BredaUniversityADSAI/2022-23d-1fcmgt-reg-ai-01-group-team9)


## Did you ensure that the AI system can be audited by independent third parties?

Yes, it is important to ensure that the AI system can be audited by independent third parties to ensure transparency and accountability. In applications affecting fundamental rights, including safety-critical applications, independent audits should be conducted to ensure the AI system meets ethical and legal standards. This does not necessarily require that information about business models and intellectual property related to the AI system must always be openly available. Our team has taken steps to do this from filling in the DEDA and ALTAI framework.

[AIframeworks](https://github.com/BredaUniversityADSAI/2022-23d-1fcmgt-reg-ai-01-group-team9/tree/main/Ethics)



## Risk Management
Both the ability to report on actions or decisions that contribute to the AI system's outcome,
and to respond to the consequences of such an outcome, must be ensured. Identifying,
assessing, documenting and minimising the potential negative impacts of AI systems is
especially crucial for those (in)directly affected. Due protection must be available for
whistle-blowers, NGOs, trade unions or other entities when reporting legitimate concerns
about an AI system.
When implementing the above requirements, tensions may arise between them, which may
lead to inevitable trade-offs. Such trade-offs should be addressed in a rational and
methodological manner within the state of the art. This entails that relevant interests and
values implicated by the AI system should be identified and that, if conflict arises, trade-offs
should be explicitly acknowledged and evaluated in terms of their risk to safety and ethical
principles, including fundamental rights. Any decision about which trade-off to make should
be well reasoned and properly documented. When adverse impact occurs, accessible
mechanisms should be foreseen that ensure adequate redress.

Did you foresee any kind of external guidance or third-party auditing processes to
oversee ethical concerns and accountability measures?
## Does the involvement of these third parties go beyond the development phase?

No third parties have been involved in the development phase and so no third parties will be a part of it in the continuation of the project's life cycle.


## Did you organise risk training and, if so, does this also inform about the potential legal framework applicable to the AI system?

Organising risk training is important to ensure all relevant parties are aware of the potential risks associated with the AI system. This training should also cover the applicable legal framework however we did not have a training seeing how this is a school project. For our project since there is no risk involved there is no reason to organize such training, however, during the development phase we have strictly followed legal frameworks regarding machine learning practices.


## Did you consider establishing an AI ethics review board or a similar mechanism to discuss the overall accountability and ethics practices, including potential unclear grey areas?

While this may be important for companies, especially working with senitive data, it may not be relevant for a school project such as ours and so we have not considered creating such a review board.


## Did you establish a process to discuss and continuously monitor and assess the AI system's adherence to this Assessment List for Trustworthy AI (ALTAI)?

We have been constatly upholding communication regarding the development process and all of our team members posses a knowledge about the ethical framework ALTAI.

[Trello](https://trello.com/b/3fUGzIHG/geoninjas)

## Does this process include identification and documentation of conflicts between the 6 aforementioned requirements or between different ethical principles and explanation of the 'trade-off' decisions made?

This process does include identifying and documenting potential risks involved in the development process.


## Did you provide appropriate training to those involved in such a process and does this also cover the legal framework applicable to the AI system?

It's essential to provide appropriate training to those involved in the process of monitoring and assessing the AI system's adherence, including covering the applicable legal framework for this school project we have not provided appropriate training because it is not applicable, however all of us have gone through learning about ALTAI.


## Did you establish a process for third parties (e.g. suppliers, end-users, subjects, distributors/vendors or workers) to report potential vulnerabilities, risks or biases in the AI system?

Yes, it's important to have a process in place for third parties to report any potential vulnerabilities, risks, or biases in the AI system. This process should also foster revision of the risk management process. This makes it not relevant for us seeing how we don't work that close with third parties that we should take into account risk management.


## Does this process foster revision of the risk management process?

We put in place checks and balances to avoid vulnerabilities that could lead to biases. This leads us to have revisions on our process. 


## For applications that can adversely affect individuals, have redress by design mechanisms been put in place?

It's important to have redress by design mechanisms in place for any applications that may have the potential to adversely affect individuals. This includes mechanisms for adequate redress when adverse impacts occur. But our application has no such risks involved and so it is irrelevant for us to create such mechanisms.
